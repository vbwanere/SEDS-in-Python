{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfAOPDZgJz0m"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as np\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "from jax import jacfwd, jacrev\n",
        "from jax.numpy import linalg\n",
        "\n",
        "from numpy import nanargmin,nanargmax\n",
        "\n",
        "key = random.PRNGKey(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2slwiA7gOe45"
      },
      "source": [
        "# Single Variable Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebUpVGzwU8Eh"
      },
      "source": [
        "Defining the Object Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REq_NrY5Nlvk"
      },
      "outputs": [],
      "source": [
        "def y(x):\n",
        "  return ((x * np.sqrt(12*x - 36 )) / (2*(x - 3)))\n",
        "def L(x):\n",
        "  return np.sqrt( x**2 + y(x)**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3cXxxCxVCWB"
      },
      "source": [
        "### Solving with Gradient Descent\n",
        "Using ***grad*** to find the derivative of the function ***L***\n",
        "\n",
        "Using ***vmap*** to map the ***minGD*** function over the ***domain***\n",
        "\n",
        "Using the gradient descent equation:\n",
        "\n",
        "$x_{n+1} = x_{n} - 0.01 L^{'}(x_{n})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdF8OOpMO0LS"
      },
      "outputs": [],
      "source": [
        "gradL = grad(L)\n",
        "\n",
        "def minGD(x): return x - 0.01 * gradL(x)\n",
        "\n",
        "domain = np.linspace(3.0, 5.0, num=50)\n",
        "\n",
        "vfuncGD = vmap(minGD)\n",
        "#Recurrent loop of gradient descent\n",
        "for epoch in range(500):\n",
        "  domain = vfuncGD(domain)\n",
        "\n",
        "minfunc = vmap(L)\n",
        "minimums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL1-aMJ_M3t7"
      },
      "source": [
        "Finding the argmin and the objective minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "P8_NnP-xhvc1",
        "outputId": "f9be9ee0-e098-4ab0-dd40-8f93e8604c28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The minimum is 7.794247150421143 the argmin is 4.505752086639404\n"
          ]
        }
      ],
      "source": [
        "arglist = nanargmin(minimums)\n",
        "argmin = domain[arglist]\n",
        "minimum = minimums[arglist]\n",
        "\n",
        "print(\"The minimum is {} the argmin is {}\".format(minimum,argmin))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cWQtt4RShjZ"
      },
      "source": [
        "### Solving with Newton's Method\n",
        "Using ***grad*** to find the derivative of the function ***L***\n",
        "\n",
        "Using ***vmap*** to map the ***minGD*** function over the ***domain***\n",
        "\n",
        "Using the gradient descent equation:\n",
        "\n",
        "$x_{n+1} = x_{n} - \\frac{L^{'}(x_{n})}{L^{''}(x_{n})} $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSWJsxTAkKvl"
      },
      "outputs": [],
      "source": [
        "gradL = grad(L)\n",
        "gradL2 = grad(gradL)\n",
        "\n",
        "def minNewton(x): return x - gradL(x)/gradL2(x)\n",
        "\n",
        "domain = np.linspace(3.0, 5.0, num=50)\n",
        "vfuncNT = vmap(minNewton)\n",
        "for epoch in range(50):\n",
        "  domain = vfuncNT(domain)\n",
        "\n",
        "minimums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw_BEFd8Tz19"
      },
      "source": [
        "Finding the argmin and the objective minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8FQhAYifzQs8",
        "outputId": "73f4c934-8092-4488-bbf3-8876a1350dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The minimum is 7.794229030609131 the arg min is 4.5\n"
          ]
        }
      ],
      "source": [
        "arglist = nanargmin(minimums)\n",
        "argmin = domain[arglist]\n",
        "minimum = minimums[arglist]\n",
        "\n",
        "print(\"The minimum is {} the argmin is {}\".format(minimum,argmin))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "babrapVGOsNB"
      },
      "source": [
        "# Multivariable Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKTRywtlUE_s"
      },
      "source": [
        "Defining the Object Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNXOUzoQzqW-"
      },
      "outputs": [],
      "source": [
        "def paraboloid(x): return (x[0]*x[1]-2)**2 + (x[1]-3)**2\n",
        "minfunc = vmap(paraboloid)\n",
        "\n",
        "J = jacfwd(paraboloid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZfP3qpIUZwj"
      },
      "source": [
        "### Solving with Gradient Descent using the Jacobian ($\\nabla f$)\n",
        "Using ***grad*** to find the jacobian of the function ***paraboloid***\n",
        "\n",
        "Using ***vmap*** to map the ***minJacobian*** function over the ***domain***\n",
        "\n",
        "Using the gradient descent equation:\n",
        "\n",
        "$X_{n+1} = X_{n} - 0.01\\nabla f(X_{n}) $\n",
        "\n",
        "Where $ X = \\left[x_1,x_2,\\ldots,x_n \\right]^T$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FT4zkldxoIZX"
      },
      "outputs": [],
      "source": [
        "def minJacobian(x): return x - 0.1*J(x)\n",
        "\n",
        "domain = random.uniform(key, shape=(50,2), dtype='float32',\n",
        "                        minval=-5.0, maxval=5.0)\n",
        "\n",
        "vfuncHS = vmap(minJacobian)\n",
        "for epoch in range(150):\n",
        "  domain = vfuncHS(domain)\n",
        "\n",
        "\n",
        "minimums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXFPZRIoZAiT"
      },
      "source": [
        "Finding the argmin and the objective minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6eNf0cj_w3hJ",
        "outputId": "3c2c3172-4793-4f43-d7ba-0aebff4358d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The minimum is 0.0 the arg min is (0.6666666865348816,3.0)\n"
          ]
        }
      ],
      "source": [
        "arglist = nanargmin(minimums)\n",
        "argmin = domain[arglist]\n",
        "minimum = minimums[arglist]\n",
        "\n",
        "print(\"The minimum is {} the arg min is ({},{})\".format(minimum,argmin[0],argmin[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUx3v1ysZRzd"
      },
      "source": [
        "Defining the Hessian as $\\nabla (\\nabla f) = \\nabla^{2}f$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VUM43RM87dR"
      },
      "outputs": [],
      "source": [
        "def hessian(f):\n",
        "    return jacfwd(jacrev(f))\n",
        "\n",
        "H = hessian(paraboloid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxCf6SfdZ2hA"
      },
      "source": [
        "### Solving with Newton's Method using the Hessian ($\\nabla^{2} f$)\n",
        "Using ***hessian*** to find the Hessian of the function ***paraboloid***\n",
        "\n",
        "Using ***vmap*** to map the ***minHessian*** function over the ***domain***\n",
        "\n",
        "Using the gradient descent equation:\n",
        "\n",
        "$X_{n+1} = X_{n} - 0.1 H^{-1}(X_{n}) \\nabla f(X_{n}) $\n",
        "\n",
        "Where $ X = \\left[x_1,x_2,\\ldots,x_n \\right]^T$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSb8zk0h9-Ju"
      },
      "outputs": [],
      "source": [
        "def minHessian(x): return x - 0.1*linalg.inv(H(x)) @ J(x)\n",
        "\n",
        "\n",
        "domain = random.uniform(key, shape=(50,2), dtype='float32',\n",
        "                        minval=-5.0, maxval=5.0)\n",
        "\n",
        "vfuncHS = vmap(minHessian)\n",
        "for epoch in range(150):\n",
        "  domain = vfuncHS(domain)\n",
        "\n",
        "\n",
        "minimums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErsWvrRybaBe"
      },
      "source": [
        "Finding the argmin and the objective minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "T_N1J8l_-8mN",
        "outputId": "df952ffe-10d2-44e2-fb35-2beb62b6244a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The minimum is 9.094947017729282e-13 the arg min is (0.6666664481163025,3.0000009536743164)\n"
          ]
        }
      ],
      "source": [
        "arglist = nanargmin(minimums)\n",
        "argmin = domain[arglist]\n",
        "minimum = minimums[arglist]\n",
        "\n",
        "print(\"The minimum is {} the arg min is ({},{})\".format(minimum,argmin[0],argmin[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTw8u2VfO2nZ"
      },
      "source": [
        "# Multivariable Constrained Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj12ffIludMv"
      },
      "source": [
        "Defining the Object Function $f(x)$\n",
        "and The Constrained Function $g(x)$\n",
        "\n",
        "The Lagrangian is defined as ***Lagrange*** $f(x) - \\lambda g(x) = 0 $\n",
        "\n",
        "Therefore using Newton's Method we solve for $Lagrange(x)=0$\n",
        "\n",
        "Which is the same as minimizing the multivariable function $\\nabla Lagrange(x)$\n",
        "\n",
        "Thus the reccurent loop is:\n",
        "$X_{n+1} = X_{n} - \\nabla^{2} Lagrange^{-1}(X_{n}) \\nabla Lagrange(X_{n}) $\n",
        "\n",
        "Where $ X = \\left[x_1,x_2,\\ldots,x_n \\right]^T$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIl0XEFQQmGk"
      },
      "outputs": [],
      "source": [
        "def f(x): return 4*(x[0]**2)*x[1]\n",
        "def g(x): return x[0]**2 + x[1]**2 - 3\n",
        "\n",
        "minfunc = vmap(f)\n",
        "\n",
        "def Lagrange(l): return f(l[0:2]) - l[3]*g(l[0:2])\n",
        "\n",
        "L = jacfwd(Lagrange)\n",
        "gradL = jacfwd(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFR44_jUT0c2"
      },
      "outputs": [],
      "source": [
        "def solveLagrangian(l): return l - linalg.inv(gradL(l)) @ L(l)\n",
        "\n",
        "\n",
        "domain = random.uniform(key, shape=(50,3), dtype='float32',\n",
        "                        minval=-5.0, maxval=5.0)\n",
        "\n",
        "vfuncsLAG = vmap(solveLagrangian)\n",
        "for epoch in range(150):\n",
        "  domain = vfuncsLAG(domain)\n",
        "\n",
        "minimums = minfunc(domain)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHHGrgWyxiZk"
      },
      "source": [
        "Finding the argmin and the objective minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "p8ZwO0A8l-PU",
        "outputId": "56f93c06-b239-4c20-bb45-3f6a0a38b18d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The minimum is -7.999999523162842, the arg min is (-1.4142135381698608,-1.0), the lagrangian is -4.0\n"
          ]
        }
      ],
      "source": [
        "arglist = nanargmin(minimums)\n",
        "argmin = domain[arglist]\n",
        "minimum = minimums[arglist]\n",
        "\n",
        "print(\"The minimum is {}, the arg min is ({},{}), the lagrangian is {}\".format(minimum,argmin[0],argmin[1],argmin[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQizl0Pi2Vm1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG8vL7Jd1GPU"
      },
      "source": [
        "# Solving a Three Variable Multivariable Constrained Optimization\n",
        "\n",
        "Find the dimensions of the box with largest volume if the total surface area is $64 cm^2$\n",
        "\n",
        "$Volume = f(x_0,x_1,x_2) = x_0 x_1x_2$\n",
        "\n",
        "$Surface Area = g(x_0,x_1,x_2) = 2x_0x_1 + 2x_1x_1 + 2x_0x_2 = 64$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdcKTxCE1MAv"
      },
      "outputs": [],
      "source": [
        "def f(x): return x[0]*x[1]*x[2]\n",
        "def g(x): return 2*x[0]*x[1] + 2*x[1]*x[2] + 2*x[0]*x[2] - 64\n",
        "\n",
        "minfunc = vmap(f)\n",
        "\n",
        "def Lagrange(l): return f(l[0:3]) - l[3]*g(l[0:3])\n",
        "\n",
        "L = jacfwd(Lagrange)\n",
        "gradL = jacfwd(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU-U0Z4W2WOg"
      },
      "outputs": [],
      "source": [
        "def solveLagrangian(l): return l - 0.1*linalg.inv(gradL(l)) @ L(l)\n",
        "\n",
        "domain = random.uniform(key, shape=(50,4), dtype='float32',\n",
        "                        minval=0, maxval=10)\n",
        "\n",
        "vfuncsLAG = vmap(solveLagrangian)\n",
        "for epoch in range(200):\n",
        "  domain = vfuncsLAG(domain)\n",
        "\n",
        "\n",
        "maximums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dDS7U7dw2ZjM",
        "outputId": "cd0568d1-b29b-485e-e3c7-4edbcc485f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The minimum is 34.83720016479492, the argmin is (3.2659873962402344,3.2659854888916016,3.2659873962402344), the lagrangian is 0.8164968490600586\n"
          ]
        }
      ],
      "source": [
        "arglist = nanargmax(maximums)\n",
        "argmin = domain[arglist]\n",
        "minimum = maximums[arglist]\n",
        "\n",
        "print(\"The minimum is {}, the argmin is ({},{},{}), the lagrangian is {}\".format(minimum,argmin[0],\n",
        "                                                                                         argmin[1],\n",
        "                                                                                         argmin[2],\n",
        "                                                                                         argmin[3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8eWqfsmH0df"
      },
      "source": [
        "It should be noted that this gives a 0.0000118855014% error!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvMt89tBEoTB"
      },
      "source": [
        "# Multivariable MultiConstrained Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-F_k9fcM8pd"
      },
      "source": [
        "Let's start by trying to maximize the object function $f(x_0,x_1)$ with the constraints $g(x_0,x_1)$ and $h(x_0,x_1)$.\n",
        "\n",
        "$f(x_0,x_1) = 13x_0*2 + 10x_0x_1+ 7x_1^2 + x_0 + x_1 +2$\n",
        "\n",
        "$g(x_0,x_1) = 2x_0 - 5x_1 - 2 $\n",
        "\n",
        "$h(x_0,x_1) = x_0 + x_1 -1$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAfygBNrEpk0"
      },
      "outputs": [],
      "source": [
        "def f(x) : return 13*x[0]**2 + 10*x[0]*x[1] + 7*x[1]**2 + x[0] + x[1]\n",
        "def g(x) : return 2*x[0]-5*x[1]-2\n",
        "def h(x) : return x[0] + x[1] -1\n",
        "\n",
        "minfunc = vmap(f)\n",
        "\n",
        "def Lagrange(l): return f(l[0:2]) - l[2]*g(l[0:2]) - l[3]*h(l[0:2])\n",
        "\n",
        "L = jacfwd(Lagrange)\n",
        "gradL = jacfwd(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJGFo_9BNm7D"
      },
      "outputs": [],
      "source": [
        "def solveLagrangian(l): return l - 0.1*linalg.inv(gradL(l)) @ L(l)\n",
        "\n",
        "\n",
        "domain = random.uniform(key, shape=(300,4), dtype='float32',\n",
        "                        minval=-4, maxval=1)\n",
        "\n",
        "\n",
        "vfuncsLAG = vmap(solveLagrangian)\n",
        "for epoch in range(300):\n",
        "  domain = vfuncsLAG(domain)\n",
        "\n",
        "\n",
        "maximums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "DFhcdCiNN7eX",
        "outputId": "76907cff-3055-46f4-9863-64ffd7e6e8a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The minimum is 13.999992370605469, the argmin is (0.9999997019767761,-1.18244605218365e-08), the lagrangians are 2.2857134342193604 and 22.428564071655273\n"
          ]
        }
      ],
      "source": [
        "arglist = nanargmin(maximums)\n",
        "argmin = domain[arglist]\n",
        "minimum = maximums[arglist]\n",
        "\n",
        "print(\"The minimum is {}, the argmin is ({},{}), the lagrangians are {} and {}\".format(minimum,argmin[0],\n",
        "                                                                                         argmin[1],\n",
        "                                                                                         argmin[2],\n",
        "                                                                                         argmin[3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XSvBlIrstyV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
